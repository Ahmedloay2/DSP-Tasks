{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e01eb24"
      },
      "outputs": [],
      "source": [
        "!pip install -q wfdb simpleaudio\n",
        "!pip install -q pyngrok flask flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cv5O8OVJIUH"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Gad-MA/Signal-Viewer-and-Classifier.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8f49597"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Add the path to the cloned repository to the system path\n",
        "repo_path = os.path.join(current_dir, 'Signal-Viewer-and-Classifier')\n",
        "sys.path.append(repo_path)\n",
        "\n",
        "# Verify the path has been added (optional)\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aliasing Audio"
      ],
      "metadata": {
        "id": "NjnuOCcAO0y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from api.aliasing.aliasing import degrade_audio"
      ],
      "metadata": {
        "id": "RPbDKJvrO0S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def alias_audio(input_filename, sampling_freq):\n",
        "  output_filename = 'degraded_version.wav'\n",
        "\n",
        "  try:\n",
        "      # 2. LOAD YOUR FILE\n",
        "      # We use sr=None to load the file at its *original* sample rate\n",
        "      print(f\"Loading '{input_filename}'...\")\n",
        "      y, sr = librosa.load(input_filename, sr=None)\n",
        "      downsample_factor = int(sr / sampling_freq)\n",
        "      print(f\"File loaded successfully. (Sample Rate: {sr} Hz, Duration: {len(y)/sr:.2f}s)\")\n",
        "\n",
        "      # 3. PROCESS THE AUDIO\n",
        "      # We pass the file's original sample rate (sr) to your function\n",
        "      print(\"Applying degradation effects...\")\n",
        "      degraded_y = degrade_audio(y, sr_high=sr, downsample_factor=downsample_factor, add_noise=False, noise_level=0.005)\n",
        "\n",
        "      # 4. SAVE THE NEW FILE\n",
        "      # We save the new file using the *same* original sample rate\n",
        "      # sf.write(output_filename, degraded_y, sr)\n",
        "      # print(f\"âœ… Success! Degraded audio saved to '{output_filename}'\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"--- ERROR ---\")\n",
        "      print(f\"File not found: '{input_filename}'\")\n",
        "      print(\"Please make sure the file is in the same directory as this script and the name is spelled correctly.\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "  return degraded_y, sr"
      ],
      "metadata": {
        "id": "J_ijQeUWXtD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anti-Aliasing"
      ],
      "metadata": {
        "id": "l-1dvC_1vMSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from api.anti_aliasing.inference import restore_and_clean_audio"
      ],
      "metadata": {
        "id": "LT5y0fUQvOWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwNWlhozvqIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gender Classification"
      ],
      "metadata": {
        "id": "fmORKeWDmC1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from api.gender_detection.gender_detection import infer_gender_from_audio"
      ],
      "metadata": {
        "id": "NeBkKuMPmFi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jIWwFukmzoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILSioKYhNIAa"
      },
      "source": [
        "# ECG Signal Retrival from Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f6adbc3"
      },
      "source": [
        "Now that the `wfdb` library is installed, you can use it to download and read the PTB-XL dataset.\n",
        "\n",
        "The `wfdb.rdrecord` function can read a single record from the dataset. You'll need to specify the record name and the directory where the dataset is stored.\n",
        "\n",
        "For the PTB-XL dataset, the records are organized in subdirectories. For example, the first record is located at `ptb-xl/1.0.3/records100/00000/00001_hr`.\n",
        "\n",
        "Let's read the first record as an example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c9e9ffc"
      },
      "source": [
        "The `record` object contains the signal data and metadata for the record.\n",
        "\n",
        "You can access the signal data using `record.p_signal` and the metadata using `record.get_annotation()`.\n",
        "\n",
        "To read multiple records or the entire dataset, you would typically iterate through the record list provided by PhysioNet for the dataset. The dataset page on PhysioNet usually provides a list of all records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f98e9fe8"
      },
      "outputs": [],
      "source": [
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import resample\n",
        "import numpy as np\n",
        "\n",
        "def retrieve_data_from_ecg_dataset(name, desired_sampling_freq=500):\n",
        "  \"\"\"\n",
        "  Retrieves ECG data from the PTB-XL dataset and resamples it to the desired frequency.\n",
        "\n",
        "  Args:\n",
        "    name (str): The name of the record to retrieve (e.g., '00001').\n",
        "    desired_sampling_freq (int): The target sampling frequency (default is 500).\n",
        "\n",
        "  Returns:\n",
        "    np.ndarray: The resampled ECG data.\n",
        "  \"\"\"\n",
        "  original_sampling_freq = 500 # The PTB-XL dataset records are originally at 500 Hz\n",
        "\n",
        "  desired_directory = f'ptb-xl/1.0.3/records{original_sampling_freq}/{name[:2]}000/'\n",
        "  record_name = f\"{name}_hr\"\n",
        "\n",
        "  record = wfdb.rdrecord(record_name, pn_dir=desired_directory)\n",
        "  ECG_data = record.p_signal\n",
        "\n",
        "  if original_sampling_freq != desired_sampling_freq:\n",
        "      # Resample the data\n",
        "      num_samples = int(len(ECG_data) * desired_sampling_freq / original_sampling_freq)\n",
        "      ECG_data = resample(ECG_data, num_samples)\n",
        "\n",
        "  return ECG_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wgizZHzNNH_"
      },
      "source": [
        "# ECG Signal Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfWPOLC0NTDY"
      },
      "outputs": [],
      "source": [
        "from api.ECG_Classifier.inference import predict_ecg_arrhythmia\n",
        "import os\n",
        "\n",
        "def classify_ecg_signal(name, desired_sampling_freq=500):\n",
        "    # desired_directory = f'ptb-xl/1.0.3/records{sampling_freq}/{name[:2]}000/'\n",
        "    # Construct the correct path to the model file\n",
        "    model_path = os.path.join('Signal-Viewer-and-Classifier', 'api', 'ECG_Classifier', 'ecg_full_model.h5')\n",
        "    return predict_ecg_arrhythmia(retrieve_data_from_ecg_dataset(name, desired_sampling_freq), model_path=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzF6NzpJ2Lpx"
      },
      "source": [
        "# Doppler Car Sound Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gKq2YkS2Qev"
      },
      "outputs": [],
      "source": [
        "from api.doppler.doppler_sound_generator import doppler_effect_wav_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k6l-swsa8EV"
      },
      "source": [
        "# Drone Sound Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIi5kPb0a7f8"
      },
      "outputs": [],
      "source": [
        "from api.drone.drones import process_drone_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUV4uXqeb2n"
      },
      "source": [
        "# SAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj5d6cF4ed9-"
      },
      "outputs": [],
      "source": [
        "from api.SAR.SAR import analyze_sar_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEEFq7VqjjmN"
      },
      "source": [
        "# EEG Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flee2VaDj8oC"
      },
      "outputs": [],
      "source": [
        "!pip install -q mne antropy awscli\n",
        "from api.EEG.Alzheimer import alzheimer_inference\n",
        "from api.EEG.parkinson import parkinson_inference\n",
        "# from api.EEG.Motor_Imagery import motor_inference\n",
        "from api.EEG.Epilepsy import epilepsy_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PQXisfHsuy_7"
      },
      "outputs": [],
      "source": [
        "# !aws s3 sync --no-sign-request s3://openneuro.org/ds004504 alzheimer_eeg_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KYpnXJ5Q7pW4"
      },
      "outputs": [],
      "source": [
        "# !aws s3 sync --no-sign-request s3://physionet-open/chbmit/1.0.0/chb02 /content/epilepsy_data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku8KGqnWNRFn"
      },
      "source": [
        "# API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDT0NI2gxFCv"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "from flask import Flask, jsonify, request, send_file\n",
        "import io\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "\n",
        "# Set your ngrok authtoken (optional but recommended)\n",
        "# Get it from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# Replace with your actual authtoken\n",
        "ngrok.set_auth_token(\"33ePdi4rrqqYDFd0PlCHMleUlX3_cmX8hBHXncgfEbzuCeS3\")\n",
        "\n",
        "# Start ngrok tunnel\n",
        "# Ensure the Flask app runs on this port\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port)\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app) # Enable CORS for all origins\n",
        "\n",
        "@app.route('/alias-speech', methods=['POST'])\n",
        "def alias_speech():\n",
        "    # Check if the request contains files\n",
        "    if 'wav_file' not in request.files:\n",
        "        return jsonify({'error': 'No file part in the request'}), 400\n",
        "\n",
        "    desired_sampling_freq = int(request.args.get('sampling_freq'))\n",
        "\n",
        "    file = request.files['wav_file']\n",
        "\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        # Securely save the file. You might want to add validation here\n",
        "        # to check if the file is actually a WAV file and sanitize the filename.\n",
        "        # For demonstration, saving to a temporary location with a fixed name.\n",
        "        # Consider using werkzeug.utils.secure_filename if saving user-provided filenames.\n",
        "        upload_dir = 'uploaded_speech_audio' # Use a specific directory for drone uploads\n",
        "        os.makedirs(upload_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "        # Using a fixed filename for simplicity in this example\n",
        "        filename = \"uploaded_speech_audio.wav\"\n",
        "        filepath = os.path.join(upload_dir, filename)\n",
        "\n",
        "        file.save(filepath)\n",
        "\n",
        "        degraded_y, sr = alias_audio(filepath, desired_sampling_freq)\n",
        "\n",
        "        # 5. Save the processed audio to an in-memory buffer\n",
        "        buffer = io.BytesIO()\n",
        "        # We use 'WAV' format and 'PCM_16' subtype for broad compatibility\n",
        "        sf.write(buffer, degraded_y, sr, format='WAV', subtype='PCM_16')\n",
        "        # Reset the buffer's position to the beginning\n",
        "        buffer.seek(0)\n",
        "\n",
        "        return send_file(\n",
        "            buffer,\n",
        "            as_attachment=True,\n",
        "            download_name='degraded_audio.wav',\n",
        "            mimetype='audio/wav'\n",
        "        )\n",
        "\n",
        "@app.route('/anti-alias', methods=['POST'])\n",
        "def anti_alias():\n",
        "    # Check if the request contains files\n",
        "    if 'wav_file' not in request.files:\n",
        "        return jsonify({'error': 'No file part in the request'}), 400\n",
        "\n",
        "    file = request.files['wav_file']\n",
        "\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        # Securely save the file. You might want to add validation here\n",
        "        # to check if the file is actually a WAV file and sanitize the filename.\n",
        "        # For demonstration, saving to a temporary location with a fixed name.\n",
        "        # Consider using werkzeug.utils.secure_filename if saving user-provided filenames.\n",
        "        upload_dir = 'uploaded_speech_audio_for_anti_alias' # Use a specific directory for drone uploads\n",
        "        os.makedirs(upload_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "        # Using a fixed filename for simplicity in this example\n",
        "        filename = \"uploaded_speech_audio_for_anti_alias.wav\"\n",
        "        filepath = os.path.join(upload_dir, filename)\n",
        "\n",
        "        file.save(filepath)\n",
        "\n",
        "        anti_aliased, final_sr = restore_and_clean_audio(filepath)\n",
        "\n",
        "        # 4. Save the processed audio to an in-memory buffer\n",
        "        buffer = io.BytesIO()\n",
        "        sf.write(buffer, anti_aliased, final_sr, format='WAV', subtype='PCM_16')\n",
        "        buffer.seek(0)\n",
        "\n",
        "        # 5. Send the buffer back as a file\n",
        "        return send_file(\n",
        "            buffer,\n",
        "            as_attachment=True,\n",
        "            download_name='anti_aliased_audio.wav',\n",
        "            mimetype='audio/wav'\n",
        "        )\n",
        "\n",
        "@app.route('/gender-classification', methods=['POST'])\n",
        "def gender_classification():\n",
        "    # Check if the request contains files\n",
        "    if 'wav_file' not in request.files:\n",
        "        return jsonify({'error': 'No file part in the request'}), 400\n",
        "    file = request.files['wav_file']\n",
        "\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        # Securely save the file. You might want to add validation here\n",
        "        # to check if the file is actually a WAV file and sanitize the filename.\n",
        "        # For demonstration, saving to a temporary location with a fixed name.\n",
        "        # Consider using werkzeug.utils.secure_filename if saving user-provided filenames.\n",
        "        upload_dir = 'uploaded_speech_audio_for_gender_classification' # Use a specific directory for drone uploads\n",
        "        os.makedirs(upload_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "        # Using a fixed filename for simplicity in this example\n",
        "        filename = \"uploaded_speech_audio_for_gender_classification.wav\"\n",
        "        filepath = os.path.join(upload_dir, filename)\n",
        "\n",
        "        file.save(filepath)\n",
        "\n",
        "        return jsonify(infer_gender_from_audio(filepath))\n",
        "\n",
        "# @app.route('/ecg_data/', defaults={'name': None}) # Handles /ecg_data/\n",
        "@app.route('/ecg_data') # Handles /ecg_data\n",
        "def get_ecg_data():\n",
        "    # Get 'name' from query parameters\n",
        "    name = request.args.get('name')\n",
        "    desired_sampling_freq = int(request.args.get('desired_sampling_freq'))\n",
        "    striped_name = str(name)[:5]\n",
        "    print(f\"Received request for name: {name}\") # Optional: for debugging\n",
        "\n",
        "    # Assuming ECG_data is a numpy array available in the global scope\n",
        "    # Convert the numpy array to a list for JSON serialization\n",
        "    ecg_data_list = retrieve_data_from_ecg_dataset(striped_name, desired_sampling_freq).tolist()\n",
        "    return jsonify(ecg_data_list)\n",
        "\n",
        "@app.route('/ecg_classification')\n",
        "def get_ecg_classification():\n",
        "    name = request.args.get('name')\n",
        "    striped_name = str(name)[:5]\n",
        "    desired_sampling_freq = int(request.args.get('desired_sampling_freq'))\n",
        "    print(f\"Received request for name: {name}\") # Optional: for debugging\n",
        "    return jsonify(classify_ecg_signal(striped_name, desired_sampling_freq))\n",
        "\n",
        "@app.route('/upload-drone-wav', methods=['POST'])\n",
        "def upload_drone_wav():\n",
        "    # Check if the request contains files\n",
        "    if 'wav_file' not in request.files:\n",
        "        return jsonify({'error': 'No file part in the request'}), 400\n",
        "\n",
        "    file = request.files['wav_file']\n",
        "\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        # Securely save the file. You might want to add validation here\n",
        "        # to check if the file is actually a WAV file and sanitize the filename.\n",
        "        # For demonstration, saving to a temporary location with a fixed name.\n",
        "        # Consider using werkzeug.utils.secure_filename if saving user-provided filenames.\n",
        "        upload_dir = 'uploaded_drone_audio' # Use a specific directory for drone uploads\n",
        "        os.makedirs(upload_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "        # Using a fixed filename for simplicity in this example\n",
        "        filename = \"uploaded_drone_audio.wav\"\n",
        "        filepath = os.path.join(upload_dir, filename)\n",
        "\n",
        "        file.save(filepath)\n",
        "\n",
        "        return process_drone_audio(filepath)\n",
        "\n",
        "@app.route('/upload-sar-image', methods=['POST'])\n",
        "def upload_sar_image():\n",
        "    # Check if the request contains files\n",
        "    if 'sar_image' not in request.files:\n",
        "        return jsonify({'error': 'No file part in the request'}), 400\n",
        "\n",
        "    file = request.files['sar_image']\n",
        "\n",
        "    # If the user does not select a file, the browser submits an\n",
        "    # empty file without a filename.\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No selected file'}), 400\n",
        "\n",
        "    if file:\n",
        "        # Securely save the file. You might want to add validation here\n",
        "        # to check if the file is actually a WAV file and sanitize the filename.\n",
        "        # For demonstration, saving to a temporary location with a fixed name.\n",
        "        # Consider using werkzeug.utils.secure_filename if saving user-provided filenames.\n",
        "        upload_dir = 'uploaded_sar_image' # Use a specific directory for drone uploads\n",
        "        os.makedirs(upload_dir, exist_ok=True) # Create directory if it doesn't exist\n",
        "        # Using a fixed filename for simplicity in this example\n",
        "        filename = \"uploaded_sar_image.bmp\"\n",
        "        filepath = os.path.join(upload_dir, filename)\n",
        "\n",
        "        file.save(filepath)\n",
        "\n",
        "        return analyze_sar_image(filepath)\n",
        "\n",
        "@app.route('/upload-eeg', methods=['POST'])\n",
        "def upload_eeg():\n",
        "    # Check if the request contains files\n",
        "    subject_num = int(request.args.get('subject_num'))\n",
        "    channel_num = int(request.args.get('channel_num'))\n",
        "    print(f\"Received request for subject_num: {subject_num}\") # Optional: for debugging\n",
        "    current_dir = os.getcwd()\n",
        "    alzheimer_eeg_data_path = os.path.join(current_dir, f'alzheimer_eeg_data/sub-{subject_num:03d}/eeg/sub-{subject_num:03d}_task-eyesclosed_eeg.set')\n",
        "    raw = mne.io.read_raw_eeglab(alzheimer_eeg_data_path)\n",
        "    number_of_channels = len(raw.info['ch_names'])\n",
        "    eeg_df = raw.to_data_frame()\n",
        "    single_channel_df = eeg_df.iloc[:5000, channel_num].tolist()\n",
        "\n",
        "    return jsonify({\n",
        "        'number_of_channels': number_of_channels,\n",
        "        # 'eeg_df': eeg_df.to_dict(orient='records')\n",
        "        'single_channel': single_channel_df\n",
        "    })\n",
        "\n",
        "@app.route('/eeg_classify', methods=['POST'])\n",
        "def eeg_classify():\n",
        "    subject_num = int(request.args.get('subject_num'))\n",
        "    return jsonify(\n",
        "      epilepsy_inference.predict_seizure(f\"/content/epilepsy_data/chb02_{subject_num:02d}.edf\")\n",
        "    )\n",
        "\n",
        "@app.route('/generate-doppler-sound', methods=['POST'])\n",
        "def generate_doppler_sound():\n",
        "    # Extract and validate parameters with defaults\n",
        "    source_velocity = request.args.get('source_velocity')\n",
        "    source_freq = request.args.get('source_freq')\n",
        "    normal_distance = request.args.get('normal_distance')\n",
        "    half_simulation_duration = request.args.get('half_simulation_duration')\n",
        "\n",
        "    # Generate the WAV file\n",
        "    doppler_effect_wav_generator(\n",
        "        source_velocity=float(source_velocity),\n",
        "        source_freq=float(source_freq),\n",
        "        normal_distance=float(normal_distance),\n",
        "        half_simulation_duration=float(half_simulation_duration)\n",
        "    )\n",
        "\n",
        "    # Construct the absolute path to the generated WAV file\n",
        "    # The file is saved in Signal-Viewer-and-Classifier/api/doppler/doppler_effect.wav\n",
        "    wav_file_relative_path_from_repo = os.path.join('api', 'doppler', 'doppler_effect.wav')\n",
        "    wav_file_absolute_path = os.path.join(repo_path, wav_file_relative_path_from_repo)\n",
        "\n",
        "    # Return the WAV file\n",
        "    return send_file(\n",
        "        wav_file_absolute_path,\n",
        "        mimetype='audio/wav',\n",
        "        as_attachment=True,\n",
        "        download_name='doppler_effect.wav'\n",
        "    )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Using threaded=False to avoid issues with Colab environment\n",
        "    app.run(port=port, threaded=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}